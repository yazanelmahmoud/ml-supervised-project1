NN (PyTorch) pipeline results [class_weight=balanced]
============================


========== NN (PyTorch) Step 1 — Width search ==========
Widths: [8, 16, 32, 64, 128, 200, 400, 700]
Mean train F1: [0.6835, 0.6841, 0.6862, 0.6876, 0.6869, 0.6873, 0.691, 0.689]
Mean CV F1:    [0.6855, 0.685, 0.6865, 0.6873, 0.6862, 0.6863, 0.6893, 0.6891]
Best width: 400
========== NN (PyTorch) Step 2 — Depth vs width ==========
Architectures: [[64], [32, 14], [28, 14, 8]]
Mean train F1: [0.6876, 0.6855, 0.6916]
Mean CV F1:    [0.6873, 0.6866, 0.6898]
Best architecture: [28, 14, 8]
========== NN (PyTorch) Step 3 — Learning rate sweep ==========
LR values: [0.1, 0.01, 0.001, 0.0003]
Mean train F1: [0.691, 0.6916, 0.0, 0.0]
Mean CV F1:    [0.7003, 0.6898, 0.0, 0.0]
Best LR: 0.1
========== NN (PyTorch) Best model ==========
Best architecture (from Step 2): [28, 14, 8]
Best learning rate (from Step 3): 0.1
Fixed: L2=0.0001, batch_size=64, early_stopping_patience=10

========== NN (PyTorch) Step 4 — Final model (test set) ==========

Learning curve (train sizes 10%, 25%, 50%, 75%, 100%):
  Train sizes: [3614, 9035, 18070, 27105, 36140]
  Train F1 (mean CV): [0.7222, 0.695, 0.6943, 0.7011, 0.7032]
  Validation F1 (mean CV): [0.7178, 0.6948, 0.6966, 0.7001, 0.7014]

Test set metrics:
  Accuracy: 0.7987
  F1: 0.6795
  PR-AUC (average_precision): 0.7804

Confusion matrix (test set):
  [[5288, 1507], [312, 1928]]

Runtime:
  Fit time: 93.8356 s
  Predict time: 0.0010 s

Training details:
  Epochs used: 244 / 500
  Early stopping: Yes
