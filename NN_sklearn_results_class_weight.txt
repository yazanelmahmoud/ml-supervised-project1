NN (sklearn) pipeline results [class_weight=balanced]
============================


========== NN (sklearn) Step 1 — Width search ==========
Widths: [8, 16, 32, 64, 128, 200, 400, 700]
Mean train F1: [0.6826, 0.6815, 0.6793, 0.6843, 0.684, 0.6857, 0.6844, 0.6863]
Mean CV F1:    [0.6805, 0.68, 0.6784, 0.6812, 0.6815, 0.6818, 0.6807, 0.6825]
Best width: 700
========== NN (sklearn) Step 2 — Depth vs width ==========
Architectures: [[64], [32, 14], [28, 14, 8]]
Mean train F1: [0.6843, 0.6811, 0.6817]
Mean CV F1:    [0.6812, 0.678, 0.6767]
Best architecture: [64]
========== NN (sklearn) Step 3 — Learning rate sweep ==========
LR values: [0.1, 0.01, 0.001, 0.0003]
Mean train F1: [0.6917, 0.6843, 0.6707, 0.6625]
Mean CV F1:    [0.6839, 0.6812, 0.6697, 0.6621]
Best LR: 0.1
========== NN (sklearn) Best model ==========
Best architecture (from Step 2): [64]
Best learning rate (from Step 3): 0.1
Fixed: L2=0.0001, batch_size=64, early_stopping_patience=10

========== NN (sklearn) Step 4 — Final model (test set) ==========

Learning curve (train sizes 10%, 25%, 50%, 75%, 100%):
  Train sizes: [2891, 7228, 14456, 21684, 28912]
  Train F1 (mean CV): [0.6924, 0.6681, 0.667, 0.6645, 0.6902]
  Validation F1 (mean CV): [0.6539, 0.6553, 0.6526, 0.6574, 0.6757]

Test set metrics:
  Accuracy: 0.8037
  F1: 0.6856
  PR-AUC (average_precision): 0.7721

Confusion matrix (test set):
  [[5327, 1468], [306, 1934]]

Runtime:
  Fit time: 2.3525 s
  Predict time: 0.0011 s

Training details:
  Iterations used: 29 / 56500
  Early stopping: Yes
