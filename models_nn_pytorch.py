"""
Neural Network â€” PyTorch MLP, SGD only.
No momentum, Nesterov, or adaptive optimizers (Adam/Adagrad/RMSprop).
Required: epoch-based learning curves; compare with sklearn MLP (optimization,
stability, runtime, tunability under SGD-only).
"""

# Placeholder: implement
# - Compact MLP in PyTorch; optimizer = SGD (no momentum)
# - Epoch-based learning curves; early stopping
# - Same capacity-scaling idea as sklearn for fair comparison

def train_and_tune_nn_pytorch(X_train, y_train, X_val, y_val):
    """Train and tune PyTorch MLP (SGD only); return best model and curves. To be implemented."""
    raise NotImplementedError("Implement PyTorch MLP training with SGD only.")
