================================================================================
  SUPPORT VECTOR MACHINES — REPORT SECTION (Adult Income Dataset)
================================================================================

We report SVM results for the Adult Income dataset using the same pipeline:
model-complexity (kernel and C), learning curves, tuning, test evaluation, and
post-mortem, tied to our hypothesis.

----------------------------------------------------------------------------
1) DATA, TASK, AND METRIC CHOICE
----------------------------------------------------------------------------

Binary classification: predict income class (<=50K vs >50K). Training set has
~3:1 class imbalance; we optimize and report F1 and PR-AUC in addition to
accuracy. F1 is the single objective for CV and model-complexity curves.
Preprocessing and leakage controls match the DT/kNN pipeline; tuning uses
5-fold stratified CV on the training set only; a single held-out test set is
used for final evaluation.

----------------------------------------------------------------------------
2) MODEL-COMPLEXITY: KERNEL, C, AND GAMMA
----------------------------------------------------------------------------

We sweep C ∈ {0.001, 0.01, 0.1, 1, 10, 100} for linear kernel and for RBF
with gamma ∈ {scale, 0.053, 0.214}. Curves show classic SVM trade-offs:
linear gives a simple boundary (high bias); RBF allows non-linear boundaries
but risks overfitting unless C and gamma are regularized.

For Adult Income:
  • Linear: CV F1 is poor across C (best ~0.51 at C=0.001), consistent with
    non-linear structure in the data that a linear boundary cannot capture.
  • RBF gamma=scale: CV F1 peaks at C=0.01 (0.6269); smaller C regularizes
    better; larger C degrades (0.47–0.49). gamma=scale (data-dependent scale)
    outperforms fixed gammas (0.053, 0.214) at best C.

Best config: kernel=rbf, C=0.01, gamma=scale; best_cv_f1: 0.6269.

[ show graphic: CV F1 vs C for linear and RBF (gamma=scale and fixed). ]

----------------------------------------------------------------------------
3) LEARNING CURVES
----------------------------------------------------------------------------

Learning curves over 10 training fractions (10%–100%) with 5-fold CV:
  • Baseline: linear, C=0.1 — train F1 ~0.40–0.68, val F1 ~0.40–0.68; gap
    small but performance modest (linear underfits).
  • Tuned: RBF C=0.01, gamma=scale — train/val F1 start near 0 for small
    fractions, then rise (val F1 → 0.6269 at full data). Tuned model needs
    sufficient data to benefit; at full data it clearly outperforms baseline.

So RBF with moderate regularization (small C) improves over linear and
matches the model-complexity finding that non-linear boundaries and
regularization are both important.

[ show graphic: learning curves — train size vs train F1 and val F1 for
  baseline (linear C=0.1) and tuned (RBF C=0.01, gamma=scale). ]

----------------------------------------------------------------------------
4) TUNING AND FINAL TEST EVALUATION
----------------------------------------------------------------------------

Best configuration from the model-complexity sweep is refit on the full
training set. No test data is used for tuning.

Best (tuned) SVM:
  kernel: rbf, C: 0.01, gamma: scale
  best_cv_f1: 0.6269

Test-set metrics:
  Accuracy: 0.6052
  F1:       0.5329
  PR-AUC:   0.6344

Runtime (reproducibility): fit ~169.7 s, predict ~10.3 s on the reported
hardware. Fit time is high due to RBF kernel on ~38k samples; predict is
slower than DT but faster than kNN (few support vectors vs full training set).

[ show graphic: ROC and/or PR curve for the test set. ]

----------------------------------------------------------------------------
5) POST-MORTEM: CONFUSION MATRIX AND INTERPRETATION
----------------------------------------------------------------------------

Confusion matrix (threshold 0.5; 0=<=50K, 1=>50K):
  TN=3433  FP=3362
  FN=205   TP=2035

The model is liberal on the positive class: many FP (3362) and few FN (205).
Recall for >50K is high; precision is moderate (TP/(TP+FP) ≈ 0.38). F1
(0.533) and PR-AUC (0.634) are below the Decision Tree (F1 0.677, PR-AUC
0.79) and kNN (F1 0.659, PR-AUC 0.74). So despite strong CV F1 (0.627), test
F1 drops—suggesting some overfitting or distribution shift, or sensitivity to
threshold; a higher threshold would reduce FP and trade off recall.

We report the default 0.5 for comparability.

[ show graphic: confusion matrix at threshold 0.5. ]

----------------------------------------------------------------------------
6) COHERENCE WITH HYPOTHESIS
----------------------------------------------------------------------------

Our hypothesis states that linear SVMs should perform moderately and RBF SVMs
should outperform them by capturing non-linear relationships, with careful
regularization for imbalance.

The results are coherent:
  • Linear SVM performs poorly (CV F1 ~0.51); RBF with C=0.01, gamma=scale
    gives best CV F1 (0.627), consistent with non-linear structure and the
    expectation that RBF > linear.
  • Small C (0.01) is chosen, consistent with “careful regularization” for
    imbalance and generalization.
  • Test F1 (0.533) and PR-AUC (0.634) are below DT and kNN on this run. So
    in our ranking, SVM does not reach “Decision Trees ≈ RBF SVMs”; the
    train–test gap (CV 0.627 vs test 0.533) suggests the RBF model may be
    overfitting or that threshold/calibration could be revisited.

In short: RBF SVM with moderate regularization (C=0.01, gamma=scale) clearly
beats linear SVM and aligns with the hypothesis that non-linear kernels and
regularization matter; final test performance is weaker than DT/kNN here,
with a liberal positive-class prediction profile.

================================================================================
