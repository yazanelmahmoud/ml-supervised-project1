{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Project 1 — Wine Quality (Red + White)\n",
        "## Supervised Learning\n",
        "\n",
        "**Task:** Multiclass classification — quality (discrete rating/class)  \n",
        "**Metrics:** Macro-F1 and Accuracy (minimum). Include confusion matrix and per-class performance discussion.  \n",
        "**Workflow:** EDA → Hypotheses → Train/tune (DT, kNN, SVM, NN-sklearn, NN-PyTorch) → Interpretation → Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 1. Setup and data loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from config import RANDOM_SEED, DATA_PATH, TARGET_COLUMN\n",
        "from utils import set_seed\n",
        "from data_loading import load_wine, get_target_and_features\n",
        "\n",
        "set_seed()\n",
        "# Load and inspect\n",
        "df = load_wine()\n",
        "X, y = get_target_and_features(df)\n",
        "print(df.shape)\n",
        "print(y.value_counts())\n",
        "print(\"\\nFirst few rows:\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 2. Exploratory Data Analysis (EDA)\n",
        "\n",
        "Class distribution, basic stats, plots. Ground for hypotheses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from eda import run_eda\n",
        "\n",
        "# Run full EDA\n",
        "eda_results = run_eda(df, save_figures=True, save_results_to_file=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 3. Preprocessing\n",
        "\n",
        "TODO: Apply preprocessing based on EDA findings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from preprocessing import get_dataset\n",
        "\n",
        "# Get preprocessed train/test splits\n",
        "X_train, y_train, X_test, y_test = get_dataset()\n",
        "\n",
        "print(f\"Training set: {X_train.shape}\")\n",
        "print(f\"Test set: {X_test.shape}\")\n",
        "print(f\"Target distribution (train):\\n{y_train.value_counts()}\")\n",
        "print(f\"Target distribution (test):\\n{y_test.value_counts()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 4. Hypotheses\n",
        "\n",
        "TODO: Develop and state hypotheses based on EDA findings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 5. Decision Trees (DT)\n",
        "\n",
        "TODO: Implement DT experiments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Implement DT experiments\n",
        "# from models_dt import run_dt_model_complexity, run_dt_learning_curves, run_dt_test_eval\n",
        "# \n",
        "# # Step 1: Model complexity\n",
        "# dt_results = run_dt_model_complexity(X_train, y_train, X_test, y_test)\n",
        "# \n",
        "# # Step 2: Learning curves\n",
        "# run_dt_learning_curves(X_train, y_train, X_test, y_test, best_config=dt_results['best_config'])\n",
        "# \n",
        "# # Step 3: Test evaluation\n",
        "# run_dt_test_eval(X_train, y_train, X_test, y_test, best_config=dt_results['best_config'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 6. k-Nearest Neighbors (kNN)\n",
        "\n",
        "TODO: Implement kNN experiments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Implement kNN experiments\n",
        "# from models_knn import run_knn_step2, run_knn_learning_curves, run_knn_test_eval\n",
        "# \n",
        "# # Step 1: Model complexity\n",
        "# knn_results = run_knn_step2(X_train, y_train, X_test, y_test)\n",
        "# \n",
        "# # Step 2: Learning curves\n",
        "# run_knn_learning_curves(X_train, y_train, X_test, y_test, best_config=knn_results['best_k_weights_metric'])\n",
        "# \n",
        "# # Step 3: Test evaluation\n",
        "# run_knn_test_eval(X_train, y_train, X_test, y_test, best_config=knn_results['best_k_weights_metric'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 7. Support Vector Machines (SVM)\n",
        "\n",
        "TODO: Implement SVM experiments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Implement SVM experiments\n",
        "# from models_svm import run_svm_model_complexity, run_svm_learning_curves, run_svm_test_eval\n",
        "# \n",
        "# # Step 1: Model complexity\n",
        "# svm_results = run_svm_model_complexity(X_train, y_train, X_test, y_test)\n",
        "# \n",
        "# # Step 2: Learning curves\n",
        "# run_svm_learning_curves(X_train, y_train, X_test, y_test, best_config=svm_results['best_config'])\n",
        "# \n",
        "# # Step 3: Test evaluation\n",
        "# run_svm_test_eval(X_train, y_train, X_test, y_test, best_config=svm_results['best_config'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 8. Neural Networks — sklearn (MLPClassifier)\n",
        "\n",
        "TODO: Implement sklearn NN experiments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Implement sklearn NN experiments\n",
        "# from models_nn_sklearn import run_nn_model_complexity, run_nn_learning_curves, run_nn_test_eval\n",
        "# \n",
        "# # Step 1: Model complexity\n",
        "# nn_sklearn_results = run_nn_model_complexity(X_train, y_train, X_test, y_test)\n",
        "# \n",
        "# # Step 2: Learning curves\n",
        "# run_nn_learning_curves(X_train, y_train, X_test, y_test, best_config=nn_sklearn_results['best_config'])\n",
        "# \n",
        "# # Step 3: Test evaluation\n",
        "# run_nn_test_eval(X_train, y_train, X_test, y_test, best_config=nn_sklearn_results['best_config'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 9. Neural Networks — PyTorch\n",
        "\n",
        "TODO: Implement PyTorch NN experiments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Implement PyTorch NN experiments\n",
        "# from models_nn_pytorch import run_nn_model_complexity, run_nn_learning_curves, run_nn_test_eval\n",
        "# \n",
        "# # Step 1: Model complexity\n",
        "# nn_pytorch_results = run_nn_model_complexity(X_train, y_train, X_test, y_test)\n",
        "# \n",
        "# # Step 2: Learning curves\n",
        "# run_nn_learning_curves(X_train, y_train, X_test, y_test, best_config=nn_pytorch_results['best_config'])\n",
        "# \n",
        "# # Step 3: Test evaluation\n",
        "# run_nn_test_eval(X_train, y_train, X_test, y_test, best_config=nn_pytorch_results['best_config'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 10. Cross-Model Comparison & Conclusions\n",
        "\n",
        "TODO: Compare all models, revisit hypotheses, discuss findings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "TODO: Write comprehensive analysis comparing all models, evaluating hypotheses, and discussing conclusions."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
