The Wine Quality dataset is a severely imbalanced 8-class numeric problem
(5,320 samples, 13 numeric features plus the target) with all features
standardized, strong linear and non-linear correlations to the target
(e.g., type, total_sulfur_dioxide, sulphates, alcohol), and redundancy among
some sulphur-related predictors.

Because the data are fully numeric and moderately high-dimensional but not
linearly separable, models that learn smooth non-linear decision boundaries
and accept class weighting (e.g., class_weight="balanced" or equivalent) are
expected to optimize macro-F1 under severe imbalance.

With and without class weighting, RBF SVMs and shallow, regularized neural
networks should perform best by capturing non-linear structure while controlling
capacity; single decision trees can exploit some interactions but, even with
class weighting, tend to create unstable, majority-dominated splits in the
presence of extreme minority classes.

Linear SVMs (even reweighted) will likely underfit because a single linear
boundary cannot capture the curved class structure implied by the correlations,
and distance-based kNN is expected to perform worst because standardized but
correlated numeric features plus imbalance make local neighborhoods dominated
by majority classes, harming minority recall and thus macro-F1.

Expected ranking (Macro-F1): RBF SVMs â‰ˆ shallow regularized NNs
> Decision Trees > Linear SVMs > kNN.