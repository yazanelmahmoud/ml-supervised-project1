Goal: Run a structured Neural Network experiment pipeline for tabular classification using SGD only.

GLOBAL SETTINGS (keep fixed unless stated otherwise):
- Optimizer: SGD (no momentum, no Adam)
- Batch size: 64
- Activation: ReLU
- Max epochs: 100
- Early stopping patience: 10
- Use stratified K-fold CV on training set (same as DT, kNN, SVM; e.g. 5-fold).
- Scale numeric features

--------------------------------------------------

STEP 1 — WIDTH SEARCH (1 hidden layer)

Architecture:
Input → Dense(W) → ReLU → Output

Hyperparameters:
- Width values: [8, 16, 32, 64, 128]
- Learning rate: 0.01
- L2: 1e-4

Run:
- For each width: stratified K-fold CV on training set.
- Record mean train F1 and mean cross-validation F1 (over folds).

PLOT:
- Model Complexity Curve
    X-axis: width
    Y-axis: mean training score + mean cross-validation score (F1)

Select the best width.

--------------------------------------------------

STEP 2 — DEPTH VS WIDTH (KEEP PARAM COUNT APPROX CONSTANT)

Test architectures:
- [64]         — Wide shallow baseline
- [32, 32]    — Balanced depth
- [16, 16, 16, 16]  — Deeper but narrower

Keep fixed:
- LR = 0.01
- L2 = 1e-4

Run:
- For each architecture: stratified K-fold CV on training set.
- Record mean train F1 and mean cross-validation F1 (over folds).

PLOT:
- Model Complexity Curve
    X-axis: number of layers (1, 2, 3)
    Y-axis: mean training score + mean cross-validation score (F1)

Select best architecture.

--------------------------------------------------

STEP 3 — LEARNING RATE SWEEP (LOG SCALE)

Use best architecture.

Test:
[0.1, 0.01, 0.001, 0.0003]

Run:
- Track loss per epoch
- Track validation metric

PLOTS:
1) Epoch Curve (REQUIRED)
    X-axis: epoch
    Y-axis: train + validation loss

2) Optional Model Complexity Curve
    X-axis: learning rate
    Y-axis: validation score

Select best LR.

--------------------------------------------------


STEP 4 — FINAL MODEL

Retrain using:
- best architecture
- best LR

Generate:

1) LEARNING CURVE
Training sizes:
[10%, 25%, 50%, 75%, 100%]

Plot:
- training score
- validation score

2) CONFUSION MATRIX

3) RUNTIME TABLE
- fit time
- predict time

--------------------------------------------------

OUTPUT CHECKLIST:
✔ Width MC curve  
✔ Depth MC curve  
✔ Epoch curve  
✔ L2 MC curve  
✔ Learning curve  
✔ Confusion matrix  
✔ Runtime table  